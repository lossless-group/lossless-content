---
site_uuid: 8cd93874-f1a6-412b-a2e4-5d77249ac0b1
url: 'https://cassandra.apache.org/'
parent_org: '[[organizations/The Apache Software Foundation]]'
image: 'https://cassandra.apache.org/_/../assets/img/logo-white-r.png'
site_name: 'Apache Cassandra'
zinger: 'Manage massive amounts of data, fast, without losing sleep'
title: 'Apache Cassandra | Apache Cassandra Documentation'
og_screenshot_url: 'https://ik.imagekit.io/xvpgfijuw/uploads/lossless/screenshots/20250529_Cassandra_og_screenshot.jpeg'
jina_last_request: '2025-03-09T06:45:05.212Z'
jina_error: 'Error occurred'
og_last_fetch: '2025-05-29T16:34:55.979Z'
date_modified: 2025-08-23
date_created: 2025-03-31
og_url: 'https://cassandra.apache.org/'
tags: [Software-Development, Databases, Big-Data-Tooling, Database]
---

A rethink of how [[concepts/Explainers for Tooling/Databases]] work. Used for [[Big Data]]

[[organizations/The Apache Software Foundation|The Apache Software Foundation]] Cassandra was indeed developed within the walls of Facebook (now Meta). The project began around 2007-2008 as a solution to handle the massive amount of data generated by the rapidly growing social network. 

Avinash Lakshman and Prashant Malik, two software engineers at Facebook, are credited with creating Cassandra. They were looking for a system that could manage large amounts of data across many commodity servers while providing high availability with no single point of failure. 

The name 'Cassandra' was inspired by the character in Greek mythology who was cursed to see events from the future but never believed by those around her, mirroring the engineers' hope that their project would predict and handle data growth effectively but might not be immediately understood or appreciated.

In 2008, Facebook open-sourced Cassandra under the Apache License. It was accepted into the Apache Incubator in January 2009 and graduated as a top-level project in February 2010. 

Since then, Cassandra has been adopted by numerous companies for its scalability and high availability, not just within the tech sector but also in finance, retail, and other industries dealing with large datasets. Its distributed design makes it particularly suitable for handling big data workloads across multiple commodity servers.